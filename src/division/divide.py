# -*- coding: utf-8 -*-
# @Author: Zhang Yuanfeng
# @Email: zhangyuanfeng1997@foxmail.com
# @Last modified time: 2024-09-25
from argparse import ArgumentParser, Namespace, RawTextHelpFormatter, ArgumentTypeError
import logging
from pathlib import Path
from pickle import load as pickle_load
import polars as pl


logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S')
logger = logging.getLogger(__name__)

DEPTH_METADATA_COLS: dict[str, str] = {'count': 'depth5_count', 'std': 'depth_std', 'max': 'depth_max',
                                       'cv': 'depth_cv', 'skew': 'depth_skew', 'kurtosis': 'depth_kurtosis',
                                       'peak_num': 'depth_peak_num', 'peak1': 'depth_peak1',
                                       'peak2': 'depth_peak2', 'peak3': 'depth_peak3',
                                       'peak4': 'depth_peak4', 'peak5': 'depth_peak5'}

BETA_METADATA_COLS: dict[str, str] = {'count': 'depth10_count', 'q5': 'beta_q5', 'q6': 'beta_q6',
                                      'q7': 'beta_q7', 'q8': 'beta_q8', 'q9': 'beta_q9',
                                      'q10': 'beta_q10', 'q11': 'beta_q11', 'q12': 'beta_q12',
                                      'q13': 'beta_q13', 'q82': 'beta_q82', 'q85': 'beta_q85',
                                      'q86': 'beta_q86', 'q87': 'beta_q87', 'q88': 'beta_q88',
                                      'q89': 'beta_q89', 'q90': 'beta_q90', 'min': 'beta_min',
                                      'max': 'beta_max', 'entropy': 'beta_entropy'}


def main():
    arg_parser: ArgumentParser = ArgumentParser(description='annotate the bedgraph and split it into 3 files.',
                                                formatter_class=RawTextHelpFormatter)
    arg_parser.add_argument('-i', '--input', type=Path, required=True, help='Input bedgraph file.')
    arg_parser.add_argument('-a', '--annotation', type=Path, required=True,
                            help='Parquet file containing annotation information, generated by annotate.py.')
    arg_parser.add_argument('-m', '--metadata', type=Path, required=True,
                            help='Pickle file containing metadata information, generated by distribution.py stat.')
    arg_parser.add_argument('-lo', '--low-depth-output', dest='lo', type=Path, required=True,
                            help='Output file for cytosines with low depth.')
    arg_parser.add_argument('-ho', '--high-depth-output', dest='ho', type=Path, required=True,
                            help='Output file for cytosines with high depth.')
    arg_parser.add_argument('-co', '--control-output', dest='co', type=Path, required=True,
                            help='Output file for conversion controls')
    arg_parser.add_argument('--controls', type=str, default='chrM,lambda,pUC19',
                            help='Comma-separated list of control contigs.')
    arg_parser.add_argument('-c', '--cutoff', type=int, default=10,
                            help='Cutoff for division, default as 10x.\n')
    arg_parser.add_argument('-f', '--force', action='store_true', default=False,
                            help='Force overwrite of output files if they exist.')

    args: Namespace = arg_parser.parse_args()
    input_path: Path = args.input
    annotation_path: Path = args.annotation
    metadata_path: Path = args.metadata
    control_output: Path = args.co
    low_depth_output: Path = args.lo
    high_depth_output: Path = args.ho
    control_contigs: list[str] = sorted(args.controls.split(','))
    cutoff: int = args.cutoff
    force_run: bool = args.force

    if cutoff < 1:
        raise ArgumentTypeError('Cutoff must be a positive integer.')

    for _p, _n in {input_path: 'Input parquet file',
                   annotation_path: 'Annotation file',
                   metadata_path: 'Metadata file'}.items():
        if not _p.exists():
            raise FileNotFoundError(f'{_n} does not exist: {_p}')

    for _p, _n in {control_output: 'Control output file',
                   low_depth_output: 'Low depth output file',
                   high_depth_output: 'High depth output file'}.items():
        if _p.exists():
            if force_run:
                logger.warning(f'{_n} already exists: {_p}, '
                               'but will be deleted and regenerated '
                               'due to --force option.')
                _p.unlink()
            else:
                raise FileExistsError(f'{_n} already exists: {_p}')

        _p.parent.mkdir(parents=True, exist_ok=True)
        logger.info(f'parent directory created: {_p.parent} for {_n}')

    logger.info('Running Config:\n'
                '=================================================='
                f'Input file: {input_path}\n'
                f'Annotation file: {annotation_path}\n'
                f'Metadata file: {args.metadata}\n'
                f'Control file: {control_output}\n'
                f'Low depth output: {low_depth_output}\n'
                f'High depth output: {high_depth_output}\n'
                f'Cutoffs: low: {cutoff}\n'
                f'Controls: {control_contigs}'
                '==================================================')

    logger.info('Reading metadata')
    with open(metadata_path, 'rb') as f:
        metadata: dict[str, str | int | float] = pickle_load(f)

    logger.info('Annotating')
    df: pl.DataFrame
    df = (pl.scan_parquet(input_path)
            .join(other=pl.scan_parquet(annotation_path)
                          .drop('strand'),
                  on=['chrom', 'start', 'end'],
                  how='left', validate='1:1')
            .with_columns([pl.lit(_v).alias(_k) for _k, _v in metadata.items()])
            .with_columns(pl.when(pl.col('beta') < 0).then(pl.lit(.0))
                            .when(pl.col('beta') > 100.0).then(pl.lit(100.0))
                            .otherwise(pl.col('beta'))
                            .cast(pl.Float64)
                            .alias('beta'))
            .rename({'beta': 'predicted_beta'})
            .collect())  # prevent illegal beta values

    logger.info(f'Annotation completed, total rows: {df.shape[0]}')

    logger.info('Dividing data into low-depth and high-depth parts based on depth')

    control_df: pl.DataFrame
    control_df = (df.lazy()
                    .filter(pl.col('chrom').is_in(control_contigs))
                    .with_columns(pl.col('predicted_beta').alias('actual_beta'))  # no calibration.
                    .collect())

    if not control_df.is_empty():
        control_df.write_parquet(control_output, compression='lz4')
        logger.info(f'conversion controls saved to {control_output}')

    (df.lazy()
       .filter((pl.col('depth') < cutoff),
               ~(pl.col('chrom').is_in(control_contigs)))
       .with_columns(pl.col('predicted_beta').alias('actual_beta'))
       .sink_parquet(low_depth_output, compression='lz4'))
    logger.info(f'cytosines with depth < {cutoff} saved to {low_depth_output}')

    (df.lazy()
       .filter(pl.col('depth') >= cutoff,
               ~pl.col('chrom').is_in(control_contigs))
       .sink_parquet(high_depth_output, compression='lz4'))
    logger.info(f'cytosines with depth >= {cutoff} saved to {high_depth_output}')
    logger.info('Data division completed')


if __name__ == '__main__':
    main()
